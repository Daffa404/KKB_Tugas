{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tugas_7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIX7D7rm6MwP"
      },
      "source": [
        "## Install python autotime untuk menghitung waktu eksekusi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRnaIiEFD8vv",
        "outputId": "5b6e5aaa-0de3-4d7e-f6c9-823ce7c0a519"
      },
      "source": [
        "!pip install ipython-autotime\r\n",
        "%load_ext autotime"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/c5/013f5aa3b56c6d2c58634bc979773df44ab2226cf4fa787daf0bfeeea0b4/ipython_autotime-0.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (51.0.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.3.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.0\n",
            "time: 158 µs (started: 2020-12-29 11:07:11 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaZSijeaHY0p"
      },
      "source": [
        "## Mendowload dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYDeumR0FLT3",
        "outputId": "cef9521f-3731-47c3-d24b-72e7ff60ffe4"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Daffa404/KKB_Tugas/master/Tugas_1/data.csv"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-29 11:50:22--  https://raw.githubusercontent.com/Daffa404/KKB_Tugas/master/Tugas_1/data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1475504 (1.4M) [text/plain]\n",
            "Saving to: ‘data.csv.1’\n",
            "\n",
            "data.csv.1          100%[===================>]   1.41M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-12-29 11:50:23 (16.4 MB/s) - ‘data.csv.1’ saved [1475504/1475504]\n",
            "\n",
            "time: 427 ms (started: 2020-12-29 11:50:22 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUN8_9cjKlyT"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5wL55kONmOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9543194-c44a-490b-db91-12dc0b63a3ac"
      },
      "source": [
        "# Util\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Model\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.optimizers import Adam # Optimizer Adam\n",
        "from keras.optimizers import SGD # Optimizer SGD\n",
        "from keras.optimizers import Ftrl # Optimizer Ftrl\n",
        "from keras.optimizers import RMSprop # Optimizer RMSprop\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Visualisasi\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count Runtime\n",
        "import time"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 6.4 ms (started: 2020-12-29 12:57:23 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43LLkc0vKiV9"
      },
      "source": [
        "## Persiapan Data Train dan Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H86cK_eJ7hJE"
      },
      "source": [
        "Meng-import file csv\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjnN5Jh_d5zF",
        "outputId": "4e5b8224-0fef-4c61-a909-03c4fb756c44"
      },
      "source": [
        "df = pd.read_csv('data.csv')\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 40.8 ms (started: 2020-12-29 12:57:26 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVkgnxY5h--d"
      },
      "source": [
        "Menampilkan data csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "nHY7XTKkh9pq",
        "outputId": "baf9e215-99b4-4995-be3a-de2ee7146be7"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Make</th>\n",
              "      <th>Model</th>\n",
              "      <th>Year</th>\n",
              "      <th>Engine Fuel Type</th>\n",
              "      <th>Engine HP</th>\n",
              "      <th>Engine Cylinders</th>\n",
              "      <th>Transmission Type</th>\n",
              "      <th>Driven_Wheels</th>\n",
              "      <th>Number of Doors</th>\n",
              "      <th>Market Category</th>\n",
              "      <th>Vehicle Size</th>\n",
              "      <th>Vehicle Style</th>\n",
              "      <th>highway MPG</th>\n",
              "      <th>city mpg</th>\n",
              "      <th>Popularity</th>\n",
              "      <th>MSRP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BMW</td>\n",
              "      <td>1 Series M</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>335.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Factory Tuner,Luxury,High-Performance</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Coupe</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "      <td>46135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BMW</td>\n",
              "      <td>1 Series</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Luxury,Performance</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Convertible</td>\n",
              "      <td>28</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "      <td>40650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BMW</td>\n",
              "      <td>1 Series</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Luxury,High-Performance</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Coupe</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>3916</td>\n",
              "      <td>36350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BMW</td>\n",
              "      <td>1 Series</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Luxury,Performance</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Coupe</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "      <td>29450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BMW</td>\n",
              "      <td>1 Series</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Luxury</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Convertible</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "      <td>34500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Make       Model  Year  ... city mpg  Popularity   MSRP\n",
              "0  BMW  1 Series M  2011  ...       19        3916  46135\n",
              "1  BMW    1 Series  2011  ...       19        3916  40650\n",
              "2  BMW    1 Series  2011  ...       20        3916  36350\n",
              "3  BMW    1 Series  2011  ...       18        3916  29450\n",
              "4  BMW    1 Series  2011  ...       18        3916  34500\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        },
        {
          "output_type": "stream",
          "text": [
            "time: 36.8 ms (started: 2020-12-29 12:57:30 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul7LNxYu8xH9"
      },
      "source": [
        "Mengambil hanya kolom yang bertipe numerik saja"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH4xzAjgeWMP",
        "outputId": "c7d80d4c-c624-4696-dc01-0281879d1c56"
      },
      "source": [
        "numeric = []\n",
        "for col in df.drop(columns=['Year','Number of Doors']).columns:\n",
        "  print(df[col].dtypes)\n",
        "  if df[col].dtypes != 'object':\n",
        "    numeric.append(col)\n",
        "numeric"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object\n",
            "object\n",
            "object\n",
            "float64\n",
            "float64\n",
            "object\n",
            "object\n",
            "object\n",
            "object\n",
            "object\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Engine HP',\n",
              " 'Engine Cylinders',\n",
              " 'highway MPG',\n",
              " 'city mpg',\n",
              " 'Popularity',\n",
              " 'MSRP']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        },
        {
          "output_type": "stream",
          "text": [
            "time: 8.07 ms (started: 2020-12-29 12:57:34 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1o1uLKV9p42"
      },
      "source": [
        "Pada target (MSRP) diubah menjadi kategorikal (cheap & expensive), kemudian diubah menjadi numerik diskrit (0: cheap & 1: expensive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Mw2cZDSDegx2",
        "outputId": "71b77354-fd1e-4a95-d6f3-99f771fc7bbb"
      },
      "source": [
        "df_num = df[numeric]\n",
        "df_num['MSRP'] = pd.qcut(df_num['MSRP'], 2, labels=['cheap', 'expensive'])\n",
        "df_num['MSRP'].replace({'cheap': 0, 'expensive': 1}, inplace=True)\n",
        "df_num.head()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Engine HP</th>\n",
              "      <th>Engine Cylinders</th>\n",
              "      <th>highway MPG</th>\n",
              "      <th>city mpg</th>\n",
              "      <th>Popularity</th>\n",
              "      <th>MSRP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>335.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>3916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Engine HP  Engine Cylinders  highway MPG  city mpg  Popularity  MSRP\n",
              "0      335.0               6.0           26        19        3916     1\n",
              "1      300.0               6.0           28        19        3916     1\n",
              "2      300.0               6.0           28        20        3916     1\n",
              "3      230.0               6.0           28        18        3916     0\n",
              "4      230.0               6.0           28        18        3916     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        },
        {
          "output_type": "stream",
          "text": [
            "time: 32.7 ms (started: 2020-12-29 12:57:39 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuQKebmcBStF"
      },
      "source": [
        "Menghilangkan baris yang memiliki missing value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSfD2kLMe2oG",
        "outputId": "4544176a-0572-4926-d7ca-dc9b3e27726a"
      },
      "source": [
        "df_num.dropna(inplace=True)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 7.17 ms (started: 2020-12-29 12:57:41 +00:00)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdeBPfB-Bsvw"
      },
      "source": [
        "Membagi data menjadi fitur (X) dan target (y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "FoFOwJJ4Bq_j",
        "outputId": "f0a63208-14fe-45d4-ae40-94fafbab3a04"
      },
      "source": [
        "X, y = df_num.drop(columns=['MSRP']), df_num['MSRP']\r\n",
        "X"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Engine HP</th>\n",
              "      <th>Engine Cylinders</th>\n",
              "      <th>highway MPG</th>\n",
              "      <th>city mpg</th>\n",
              "      <th>Popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>335.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11909</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11910</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11911</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11912</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11913</th>\n",
              "      <td>221.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>26</td>\n",
              "      <td>17</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11816 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Engine HP  Engine Cylinders  highway MPG  city mpg  Popularity\n",
              "0          335.0               6.0           26        19        3916\n",
              "1          300.0               6.0           28        19        3916\n",
              "2          300.0               6.0           28        20        3916\n",
              "3          230.0               6.0           28        18        3916\n",
              "4          230.0               6.0           28        18        3916\n",
              "...          ...               ...          ...       ...         ...\n",
              "11909      300.0               6.0           23        16         204\n",
              "11910      300.0               6.0           23        16         204\n",
              "11911      300.0               6.0           23        16         204\n",
              "11912      300.0               6.0           23        16         204\n",
              "11913      221.0               6.0           26        17          61\n",
              "\n",
              "[11816 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        },
        {
          "output_type": "stream",
          "text": [
            "time: 22 ms (started: 2020-12-29 12:57:44 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2weQqeQQCgSM"
      },
      "source": [
        "Melakukan normalisasi pada setiap fitur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO72qqRxfEZt",
        "outputId": "4300b011-2809-41c8-ef2a-639f81ccf493"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29598309, 0.375     , 0.04093567, 0.09230769, 0.69213086],\n",
              "       [0.2589852 , 0.375     , 0.04678363, 0.09230769, 0.69213086],\n",
              "       [0.2589852 , 0.375     , 0.04678363, 0.1       , 0.69213086],\n",
              "       ...,\n",
              "       [0.2589852 , 0.375     , 0.03216374, 0.06923077, 0.0357206 ],\n",
              "       [0.2589852 , 0.375     , 0.03216374, 0.06923077, 0.0357206 ],\n",
              "       [0.17547569, 0.375     , 0.04093567, 0.07692308, 0.01043324]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        },
        {
          "output_type": "stream",
          "text": [
            "time: 8.57 ms (started: 2020-12-29 12:57:49 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pncn3sl2D6Px"
      },
      "source": [
        "Membagi data menjadi train dan test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJZJR8-efP0c",
        "outputId": "7bcfe15c-5a17-4362-f1e9-454164836e21"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.7, random_state=42)\n",
        "print(len(X_train), len(y_train), len(X_test), len(y_test))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3544 3544 8272 8272\n",
            "time: 7.83 ms (started: 2020-12-29 13:24:46 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rrfi0t8Pfc7g"
      },
      "source": [
        "Mengubah dataframe menjadi 3 dimensi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FGWj62WfeTD",
        "outputId": "a5101085-f9cc-4f19-d616-bc0a95fbe5f9"
      },
      "source": [
        "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_train_reshaped.shape[1:3]"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        },
        {
          "output_type": "stream",
          "text": [
            "time: 3.49 ms (started: 2020-12-29 13:24:48 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bncmyDZQf0uy",
        "outputId": "47d25f11-a14c-4e74-b61d-de791853d724"
      },
      "source": [
        "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "X_test_reshaped.shape"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8272, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        },
        {
          "output_type": "stream",
          "text": [
            "time: 2.69 ms (started: 2020-12-29 13:24:51 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLMEKq6hG67L"
      },
      "source": [
        "Menambahkan conv layer 1, conv layer 2, dan output layer pada CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN4mM_SIf5eS",
        "outputId": "6061a7fd-90b1-480e-be29-91830add34bf"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Hidden Layer 1\n",
        "model.add(Conv1D(32, 4, input_shape=X_train_reshaped.shape[1:3], activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(1))\n",
        "\n",
        "# Hidden Layer 2\n",
        "model.add(Conv1D(16, 2, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_28 (Conv1D)           (None, 2, 32)             160       \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 2, 32)             0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_28 (MaxPooling (None, 2, 32)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_29 (Conv1D)           (None, 1, 16)             1040      \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 1, 16)             0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_29 (MaxPooling (None, 1, 16)             0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,217\n",
            "Trainable params: 1,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "time: 69 ms (started: 2020-12-29 13:24:53 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5N1etQrKGO0"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZTHxXXgQdxR"
      },
      "source": [
        "Kami menyediakan beberapa pilihan optimizer, Silahkan di run salah satu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXLWJxr6Fvg4"
      },
      "source": [
        "Menggunakan SGD optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLmVYibPEGcb",
        "outputId": "b212e716-a178-4337-eacb-df09c7aefbb1"
      },
      "source": [
        "optimizer = SGD(\r\n",
        "    learning_rate=0.01, momentum=0.0, nesterov=False, name=\"SGD\")"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.22 ms (started: 2020-12-29 13:03:32 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m50y1PkNF0Fa"
      },
      "source": [
        "Menggunakan Adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcUr8bnbEw-Y",
        "outputId": "b6cb520c-6009-4705-9706-91e7d6e02a8f"
      },
      "source": [
        "optimizer = Adam(learning_rate=0.01, name=\"Adam\")"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.08 ms (started: 2020-12-29 12:58:04 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp_7WaVoJ5ct"
      },
      "source": [
        "Menggunkan Ftrl optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ca31GyYISpJ",
        "outputId": "e29216e3-d28e-430e-ce0d-08f94860f68b"
      },
      "source": [
        "optimizer = Ftrl(\r\n",
        "    learning_rate=0.01,\r\n",
        "    learning_rate_power=-0.5,\r\n",
        "    initial_accumulator_value=0.1,\r\n",
        "    l1_regularization_strength=0.0,\r\n",
        "    l2_regularization_strength=0.0,\r\n",
        "    name=\"Ftrl\",\r\n",
        "    l2_shrinkage_regularization_strength=0.0,\r\n",
        "    beta=0.0,\r\n",
        ")"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.55 ms (started: 2020-12-29 13:24:59 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2rpmiClkiT6"
      },
      "source": [
        "Menggunakan RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nco5JYaRkcMW",
        "outputId": "0f514d25-1ec2-4c90-ad76-d3f82eeacb35"
      },
      "source": [
        "optimizer = RMSprop(\r\n",
        "    learning_rate=0.01,\r\n",
        "    rho=0.9,\r\n",
        "    momentum=0.0,\r\n",
        "    epsilon=1e-07,\r\n",
        "    centered=False,\r\n",
        "    name=\"RMSprop\",\r\n",
        ")"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.86 ms (started: 2020-12-29 13:27:50 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abp2Ikz5KRA_"
      },
      "source": [
        "##Early Stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuuUo5tyKzRU"
      },
      "source": [
        "Menambahkan early stopping untuk menghentikan iterasi ketika setelah beberapa iterasi akurasi tidak bertambah"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nou5N7CVgD1u",
        "outputId": "effe3551-9bb2-4bb3-c77d-2e4796426416"
      },
      "source": [
        "%%time\n",
        "early_stopping_monitor = EarlyStopping(\n",
        "    monitor='accuracy',\n",
        "    min_delta=0,\n",
        "    patience=100,\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics='accuracy')\n",
        "\n",
        "history = model.fit(X_train_reshaped, y_train,\n",
        "          epochs=1000, \n",
        "          verbose=1,\n",
        "          validation_data=(X_test_reshaped, y_test),\n",
        "          callbacks=[early_stopping_monitor])"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6694 - accuracy: 0.5599 - val_loss: 0.5204 - val_accuracy: 0.8119\n",
            "Epoch 2/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7880 - val_loss: 0.3990 - val_accuracy: 0.8566\n",
            "Epoch 3/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8269 - val_loss: 0.3582 - val_accuracy: 0.8605\n",
            "Epoch 4/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8428 - val_loss: 0.3487 - val_accuracy: 0.8667\n",
            "Epoch 5/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8229 - val_loss: 0.3431 - val_accuracy: 0.8648\n",
            "Epoch 6/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8439 - val_loss: 0.3411 - val_accuracy: 0.8615\n",
            "Epoch 7/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8245 - val_loss: 0.3448 - val_accuracy: 0.8581\n",
            "Epoch 8/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8347 - val_loss: 0.3400 - val_accuracy: 0.8659\n",
            "Epoch 9/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8580 - val_loss: 0.3378 - val_accuracy: 0.8677\n",
            "Epoch 10/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8492 - val_loss: 0.3383 - val_accuracy: 0.8667\n",
            "Epoch 11/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8417 - val_loss: 0.3779 - val_accuracy: 0.8632\n",
            "Epoch 12/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8241 - val_loss: 0.3820 - val_accuracy: 0.8650\n",
            "Epoch 13/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8299 - val_loss: 0.3399 - val_accuracy: 0.8677\n",
            "Epoch 14/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8292 - val_loss: 0.3404 - val_accuracy: 0.8686\n",
            "Epoch 15/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8454 - val_loss: 0.3425 - val_accuracy: 0.8662\n",
            "Epoch 16/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8265 - val_loss: 0.3407 - val_accuracy: 0.8613\n",
            "Epoch 17/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8422 - val_loss: 0.3434 - val_accuracy: 0.8686\n",
            "Epoch 18/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3742 - accuracy: 0.8481 - val_loss: 0.3416 - val_accuracy: 0.8658\n",
            "Epoch 19/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8310 - val_loss: 0.3500 - val_accuracy: 0.8522\n",
            "Epoch 20/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8312 - val_loss: 0.3433 - val_accuracy: 0.8693\n",
            "Epoch 21/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8361 - val_loss: 0.3426 - val_accuracy: 0.8564\n",
            "Epoch 22/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.8541 - val_loss: 0.3610 - val_accuracy: 0.8658\n",
            "Epoch 23/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8400 - val_loss: 0.3396 - val_accuracy: 0.8690\n",
            "Epoch 24/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3693 - accuracy: 0.8516 - val_loss: 0.3382 - val_accuracy: 0.8633\n",
            "Epoch 25/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8298 - val_loss: 0.3431 - val_accuracy: 0.8659\n",
            "Epoch 26/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8255 - val_loss: 0.3405 - val_accuracy: 0.8693\n",
            "Epoch 27/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8449 - val_loss: 0.3384 - val_accuracy: 0.8617\n",
            "Epoch 28/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8390 - val_loss: 0.3490 - val_accuracy: 0.8698\n",
            "Epoch 29/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8381 - val_loss: 0.3503 - val_accuracy: 0.8694\n",
            "Epoch 30/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8432 - val_loss: 0.3380 - val_accuracy: 0.8687\n",
            "Epoch 31/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8438 - val_loss: 0.3422 - val_accuracy: 0.8669\n",
            "Epoch 32/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8436 - val_loss: 0.3406 - val_accuracy: 0.8668\n",
            "Epoch 33/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8369 - val_loss: 0.3393 - val_accuracy: 0.8680\n",
            "Epoch 34/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8388 - val_loss: 0.3441 - val_accuracy: 0.8692\n",
            "Epoch 35/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8354 - val_loss: 0.3408 - val_accuracy: 0.8691\n",
            "Epoch 36/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8356 - val_loss: 0.3477 - val_accuracy: 0.8686\n",
            "Epoch 37/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8479 - val_loss: 0.3372 - val_accuracy: 0.8581\n",
            "Epoch 38/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8426 - val_loss: 0.3434 - val_accuracy: 0.8549\n",
            "Epoch 39/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8391 - val_loss: 0.3416 - val_accuracy: 0.8688\n",
            "Epoch 40/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4051 - accuracy: 0.8366 - val_loss: 0.3386 - val_accuracy: 0.8661\n",
            "Epoch 41/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8389 - val_loss: 0.3493 - val_accuracy: 0.8519\n",
            "Epoch 42/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8418 - val_loss: 0.3413 - val_accuracy: 0.8647\n",
            "Epoch 43/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8430 - val_loss: 0.3402 - val_accuracy: 0.8669\n",
            "Epoch 44/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8240 - val_loss: 0.3389 - val_accuracy: 0.8694\n",
            "Epoch 45/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8402 - val_loss: 0.3574 - val_accuracy: 0.8658\n",
            "Epoch 46/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8303 - val_loss: 0.3574 - val_accuracy: 0.8549\n",
            "Epoch 47/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8422 - val_loss: 0.3696 - val_accuracy: 0.8495\n",
            "Epoch 48/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8414 - val_loss: 0.3531 - val_accuracy: 0.8546\n",
            "Epoch 49/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8452 - val_loss: 0.3698 - val_accuracy: 0.8634\n",
            "Epoch 50/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8425 - val_loss: 0.3387 - val_accuracy: 0.8673\n",
            "Epoch 51/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8288 - val_loss: 0.3374 - val_accuracy: 0.8680\n",
            "Epoch 52/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8352 - val_loss: 0.3410 - val_accuracy: 0.8684\n",
            "Epoch 53/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8371 - val_loss: 0.3459 - val_accuracy: 0.8515\n",
            "Epoch 54/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8386 - val_loss: 0.3549 - val_accuracy: 0.8676\n",
            "Epoch 55/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8449 - val_loss: 0.3572 - val_accuracy: 0.8671\n",
            "Epoch 56/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8448 - val_loss: 0.3418 - val_accuracy: 0.8536\n",
            "Epoch 57/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3634 - accuracy: 0.8479 - val_loss: 0.3396 - val_accuracy: 0.8674\n",
            "Epoch 58/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8300 - val_loss: 0.3395 - val_accuracy: 0.8589\n",
            "Epoch 59/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8344 - val_loss: 0.3400 - val_accuracy: 0.8599\n",
            "Epoch 60/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8389 - val_loss: 0.3429 - val_accuracy: 0.8705\n",
            "Epoch 61/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8544 - val_loss: 0.3646 - val_accuracy: 0.8526\n",
            "Epoch 62/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8375 - val_loss: 0.3438 - val_accuracy: 0.8690\n",
            "Epoch 63/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8434 - val_loss: 0.3393 - val_accuracy: 0.8700\n",
            "Epoch 64/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8391 - val_loss: 0.3414 - val_accuracy: 0.8691\n",
            "Epoch 65/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8396 - val_loss: 0.3372 - val_accuracy: 0.8604\n",
            "Epoch 66/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8328 - val_loss: 0.3380 - val_accuracy: 0.8662\n",
            "Epoch 67/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8405 - val_loss: 0.3394 - val_accuracy: 0.8667\n",
            "Epoch 68/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3930 - accuracy: 0.8398 - val_loss: 0.3460 - val_accuracy: 0.8682\n",
            "Epoch 69/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3869 - accuracy: 0.8446 - val_loss: 0.3423 - val_accuracy: 0.8677\n",
            "Epoch 70/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8397 - val_loss: 0.3583 - val_accuracy: 0.8691\n",
            "Epoch 71/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.8456 - val_loss: 0.3398 - val_accuracy: 0.8696\n",
            "Epoch 72/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8377 - val_loss: 0.3394 - val_accuracy: 0.8646\n",
            "Epoch 73/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8322 - val_loss: 0.3376 - val_accuracy: 0.8646\n",
            "Epoch 74/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3730 - accuracy: 0.8510 - val_loss: 0.3567 - val_accuracy: 0.8547\n",
            "Epoch 75/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8252 - val_loss: 0.3368 - val_accuracy: 0.8587\n",
            "Epoch 76/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8347 - val_loss: 0.3725 - val_accuracy: 0.8450\n",
            "Epoch 77/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8334 - val_loss: 0.3415 - val_accuracy: 0.8548\n",
            "Epoch 78/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8464 - val_loss: 0.3484 - val_accuracy: 0.8555\n",
            "Epoch 79/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8463 - val_loss: 0.3499 - val_accuracy: 0.8680\n",
            "Epoch 80/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8382 - val_loss: 0.3435 - val_accuracy: 0.8669\n",
            "Epoch 81/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8598 - val_loss: 0.3361 - val_accuracy: 0.8635\n",
            "Epoch 82/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8532 - val_loss: 0.3386 - val_accuracy: 0.8675\n",
            "Epoch 83/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8407 - val_loss: 0.3386 - val_accuracy: 0.8669\n",
            "Epoch 84/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8310 - val_loss: 0.3434 - val_accuracy: 0.8692\n",
            "Epoch 85/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.8431 - val_loss: 0.3398 - val_accuracy: 0.8610\n",
            "Epoch 86/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.8615 - val_loss: 0.3380 - val_accuracy: 0.8667\n",
            "Epoch 87/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8350 - val_loss: 0.3375 - val_accuracy: 0.8674\n",
            "Epoch 88/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8525 - val_loss: 0.3484 - val_accuracy: 0.8708\n",
            "Epoch 89/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8483 - val_loss: 0.3374 - val_accuracy: 0.8671\n",
            "Epoch 90/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3930 - accuracy: 0.8419 - val_loss: 0.3396 - val_accuracy: 0.8687\n",
            "Epoch 91/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8414 - val_loss: 0.3451 - val_accuracy: 0.8688\n",
            "Epoch 92/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.8422 - val_loss: 0.3727 - val_accuracy: 0.8409\n",
            "Epoch 93/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8410 - val_loss: 0.3524 - val_accuracy: 0.8569\n",
            "Epoch 94/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8418 - val_loss: 0.3389 - val_accuracy: 0.8613\n",
            "Epoch 95/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8432 - val_loss: 0.3843 - val_accuracy: 0.8641\n",
            "Epoch 96/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8281 - val_loss: 0.3643 - val_accuracy: 0.8664\n",
            "Epoch 97/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8257 - val_loss: 0.3594 - val_accuracy: 0.8654\n",
            "Epoch 98/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8422 - val_loss: 0.3392 - val_accuracy: 0.8681\n",
            "Epoch 99/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3850 - accuracy: 0.8402 - val_loss: 0.3685 - val_accuracy: 0.8497\n",
            "Epoch 100/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8392 - val_loss: 0.3360 - val_accuracy: 0.8593\n",
            "Epoch 101/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8405 - val_loss: 0.3399 - val_accuracy: 0.8694\n",
            "Epoch 102/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8386 - val_loss: 0.3444 - val_accuracy: 0.8692\n",
            "Epoch 103/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8460 - val_loss: 0.3549 - val_accuracy: 0.8554\n",
            "Epoch 104/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8264 - val_loss: 0.3382 - val_accuracy: 0.8596\n",
            "Epoch 105/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3564 - accuracy: 0.8527 - val_loss: 0.3445 - val_accuracy: 0.8692\n",
            "Epoch 106/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8330 - val_loss: 0.3462 - val_accuracy: 0.8537\n",
            "Epoch 107/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3889 - accuracy: 0.8446 - val_loss: 0.3919 - val_accuracy: 0.8240\n",
            "Epoch 108/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8352 - val_loss: 0.3356 - val_accuracy: 0.8669\n",
            "Epoch 109/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8395 - val_loss: 0.3372 - val_accuracy: 0.8648\n",
            "Epoch 110/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8320 - val_loss: 0.3395 - val_accuracy: 0.8651\n",
            "Epoch 111/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8427 - val_loss: 0.3590 - val_accuracy: 0.8654\n",
            "Epoch 112/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8336 - val_loss: 0.3389 - val_accuracy: 0.8659\n",
            "Epoch 113/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8338 - val_loss: 0.3387 - val_accuracy: 0.8603\n",
            "Epoch 114/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8322 - val_loss: 0.3381 - val_accuracy: 0.8612\n",
            "Epoch 115/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8445 - val_loss: 0.3399 - val_accuracy: 0.8572\n",
            "Epoch 116/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8444 - val_loss: 0.3390 - val_accuracy: 0.8667\n",
            "Epoch 117/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3911 - accuracy: 0.8408 - val_loss: 0.3397 - val_accuracy: 0.8656\n",
            "Epoch 118/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8403 - val_loss: 0.3357 - val_accuracy: 0.8670\n",
            "Epoch 119/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8350 - val_loss: 0.3432 - val_accuracy: 0.8679\n",
            "Epoch 120/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8358 - val_loss: 0.3824 - val_accuracy: 0.8645\n",
            "Epoch 121/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8339 - val_loss: 0.3584 - val_accuracy: 0.8687\n",
            "Epoch 122/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8418 - val_loss: 0.3456 - val_accuracy: 0.8546\n",
            "Epoch 123/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8403 - val_loss: 0.3456 - val_accuracy: 0.8535\n",
            "Epoch 124/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4008 - accuracy: 0.8328 - val_loss: 0.3387 - val_accuracy: 0.8584\n",
            "Epoch 125/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3750 - accuracy: 0.8497 - val_loss: 0.3404 - val_accuracy: 0.8693\n",
            "Epoch 126/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.8408 - val_loss: 0.3413 - val_accuracy: 0.8541\n",
            "Epoch 127/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8397 - val_loss: 0.3393 - val_accuracy: 0.8635\n",
            "Epoch 128/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8467 - val_loss: 0.3396 - val_accuracy: 0.8544\n",
            "Epoch 129/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8387 - val_loss: 0.3402 - val_accuracy: 0.8590\n",
            "Epoch 130/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8310 - val_loss: 0.3487 - val_accuracy: 0.8676\n",
            "Epoch 131/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8387 - val_loss: 0.3442 - val_accuracy: 0.8691\n",
            "Epoch 132/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8330 - val_loss: 0.4013 - val_accuracy: 0.8641\n",
            "Epoch 133/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8424 - val_loss: 0.3422 - val_accuracy: 0.8581\n",
            "Epoch 134/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8455 - val_loss: 0.3460 - val_accuracy: 0.8700\n",
            "Epoch 135/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3770 - accuracy: 0.8495 - val_loss: 0.3404 - val_accuracy: 0.8691\n",
            "Epoch 136/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8470 - val_loss: 0.3544 - val_accuracy: 0.8567\n",
            "Epoch 137/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8345 - val_loss: 0.3376 - val_accuracy: 0.8578\n",
            "Epoch 138/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8353 - val_loss: 0.3426 - val_accuracy: 0.8558\n",
            "Epoch 139/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8321 - val_loss: 0.3405 - val_accuracy: 0.8634\n",
            "Epoch 140/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3782 - accuracy: 0.8395 - val_loss: 0.3465 - val_accuracy: 0.8702\n",
            "Epoch 141/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8407 - val_loss: 0.3480 - val_accuracy: 0.8694\n",
            "Epoch 142/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8326 - val_loss: 0.3411 - val_accuracy: 0.8578\n",
            "Epoch 143/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8463 - val_loss: 0.3365 - val_accuracy: 0.8679\n",
            "Epoch 144/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3850 - accuracy: 0.8410 - val_loss: 0.3414 - val_accuracy: 0.8668\n",
            "Epoch 145/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8370 - val_loss: 0.3390 - val_accuracy: 0.8606\n",
            "Epoch 146/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8465 - val_loss: 0.3969 - val_accuracy: 0.8644\n",
            "Epoch 147/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3770 - accuracy: 0.8448 - val_loss: 0.3388 - val_accuracy: 0.8632\n",
            "Epoch 148/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8431 - val_loss: 0.3405 - val_accuracy: 0.8635\n",
            "Epoch 149/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8541 - val_loss: 0.3433 - val_accuracy: 0.8703\n",
            "Epoch 150/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8461 - val_loss: 0.3409 - val_accuracy: 0.8641\n",
            "Epoch 151/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8540 - val_loss: 0.3794 - val_accuracy: 0.8351\n",
            "Epoch 152/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8368 - val_loss: 0.3394 - val_accuracy: 0.8600\n",
            "Epoch 153/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8378 - val_loss: 0.3388 - val_accuracy: 0.8676\n",
            "Epoch 154/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8356 - val_loss: 0.3438 - val_accuracy: 0.8703\n",
            "Epoch 155/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8478 - val_loss: 0.3432 - val_accuracy: 0.8703\n",
            "Epoch 156/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8365 - val_loss: 0.3376 - val_accuracy: 0.8609\n",
            "Epoch 157/1000\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 0.3685 - accuracy: 0.8448 - val_loss: 0.3435 - val_accuracy: 0.8686\n",
            "Epoch 158/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8278 - val_loss: 0.3460 - val_accuracy: 0.8664\n",
            "Epoch 159/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.8488 - val_loss: 0.3580 - val_accuracy: 0.8674\n",
            "Epoch 160/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8404 - val_loss: 0.3429 - val_accuracy: 0.8700\n",
            "Epoch 161/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8495 - val_loss: 0.3409 - val_accuracy: 0.8706\n",
            "Epoch 162/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8415 - val_loss: 0.3383 - val_accuracy: 0.8623\n",
            "Epoch 163/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8394 - val_loss: 0.3648 - val_accuracy: 0.8670\n",
            "Epoch 164/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8478 - val_loss: 0.3419 - val_accuracy: 0.8534\n",
            "Epoch 165/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.8375 - val_loss: 0.3459 - val_accuracy: 0.8690\n",
            "Epoch 166/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8389 - val_loss: 0.3415 - val_accuracy: 0.8534\n",
            "Epoch 167/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8314 - val_loss: 0.3521 - val_accuracy: 0.8692\n",
            "Epoch 168/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8606 - val_loss: 0.3550 - val_accuracy: 0.8569\n",
            "Epoch 169/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8289 - val_loss: 0.3381 - val_accuracy: 0.8600\n",
            "Epoch 170/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8318 - val_loss: 0.3407 - val_accuracy: 0.8642\n",
            "Epoch 171/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3774 - accuracy: 0.8425 - val_loss: 0.3403 - val_accuracy: 0.8600\n",
            "Epoch 172/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8330 - val_loss: 0.3974 - val_accuracy: 0.8636\n",
            "Epoch 173/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8445 - val_loss: 0.3550 - val_accuracy: 0.8702\n",
            "Epoch 174/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3638 - accuracy: 0.8490 - val_loss: 0.3420 - val_accuracy: 0.8538\n",
            "Epoch 175/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8334 - val_loss: 0.3481 - val_accuracy: 0.8703\n",
            "Epoch 176/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.8548 - val_loss: 0.3396 - val_accuracy: 0.8662\n",
            "Epoch 177/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8342 - val_loss: 0.3634 - val_accuracy: 0.8664\n",
            "Epoch 178/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8526 - val_loss: 0.4148 - val_accuracy: 0.8621\n",
            "Epoch 179/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8439 - val_loss: 0.3425 - val_accuracy: 0.8543\n",
            "Epoch 180/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8407 - val_loss: 0.3420 - val_accuracy: 0.8560\n",
            "Epoch 181/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8470 - val_loss: 0.3384 - val_accuracy: 0.8662\n",
            "Epoch 182/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.8412 - val_loss: 0.3411 - val_accuracy: 0.8560\n",
            "Epoch 183/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8449 - val_loss: 0.3363 - val_accuracy: 0.8656\n",
            "Epoch 184/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8455 - val_loss: 0.3399 - val_accuracy: 0.8543\n",
            "Epoch 185/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8470 - val_loss: 0.3401 - val_accuracy: 0.8650\n",
            "Epoch 186/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3694 - accuracy: 0.8564 - val_loss: 0.3524 - val_accuracy: 0.8569\n",
            "Epoch 187/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8362 - val_loss: 0.3438 - val_accuracy: 0.8709\n",
            "Epoch 188/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8478 - val_loss: 0.3595 - val_accuracy: 0.8552\n",
            "Epoch 189/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8435 - val_loss: 0.3403 - val_accuracy: 0.8537\n",
            "Epoch 190/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3870 - accuracy: 0.8339 - val_loss: 0.3445 - val_accuracy: 0.8700\n",
            "Epoch 191/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8455 - val_loss: 0.3409 - val_accuracy: 0.8662\n",
            "Epoch 192/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3708 - accuracy: 0.8478 - val_loss: 0.3372 - val_accuracy: 0.8676\n",
            "Epoch 193/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8394 - val_loss: 0.3362 - val_accuracy: 0.8674\n",
            "Epoch 194/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8265 - val_loss: 0.3418 - val_accuracy: 0.8671\n",
            "Epoch 195/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8406 - val_loss: 0.3413 - val_accuracy: 0.8534\n",
            "Epoch 196/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8546 - val_loss: 0.3372 - val_accuracy: 0.8677\n",
            "Epoch 197/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8387 - val_loss: 0.3604 - val_accuracy: 0.8542\n",
            "Epoch 198/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8285 - val_loss: 0.3564 - val_accuracy: 0.8567\n",
            "Epoch 199/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8348 - val_loss: 0.3406 - val_accuracy: 0.8638\n",
            "Epoch 200/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8475 - val_loss: 0.3365 - val_accuracy: 0.8634\n",
            "Epoch 201/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8280 - val_loss: 0.3383 - val_accuracy: 0.8635\n",
            "Epoch 202/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.8424 - val_loss: 0.3404 - val_accuracy: 0.8658\n",
            "Epoch 203/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8412 - val_loss: 0.3402 - val_accuracy: 0.8625\n",
            "Epoch 204/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8416 - val_loss: 0.3497 - val_accuracy: 0.8558\n",
            "Epoch 205/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.8358 - val_loss: 0.3381 - val_accuracy: 0.8669\n",
            "Epoch 206/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3776 - accuracy: 0.8548 - val_loss: 0.3367 - val_accuracy: 0.8634\n",
            "Epoch 207/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3883 - accuracy: 0.8351 - val_loss: 0.3494 - val_accuracy: 0.8576\n",
            "Epoch 208/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8353 - val_loss: 0.3379 - val_accuracy: 0.8634\n",
            "Epoch 209/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8432 - val_loss: 0.3413 - val_accuracy: 0.8691\n",
            "Epoch 210/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.8387 - val_loss: 0.3450 - val_accuracy: 0.8697\n",
            "Epoch 211/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8431 - val_loss: 0.3401 - val_accuracy: 0.8659\n",
            "Epoch 212/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8343 - val_loss: 0.3867 - val_accuracy: 0.8629\n",
            "Epoch 213/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8379 - val_loss: 0.3503 - val_accuracy: 0.8702\n",
            "Epoch 214/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8367 - val_loss: 0.3432 - val_accuracy: 0.8581\n",
            "Epoch 215/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8490 - val_loss: 0.3529 - val_accuracy: 0.8696\n",
            "Epoch 216/1000\n",
            "111/111 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8438 - val_loss: 0.3418 - val_accuracy: 0.8581\n",
            "Epoch 217/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8406 - val_loss: 0.3398 - val_accuracy: 0.8619\n",
            "Epoch 218/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8362 - val_loss: 0.3463 - val_accuracy: 0.8708\n",
            "Epoch 219/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8465 - val_loss: 0.3395 - val_accuracy: 0.8665\n",
            "Epoch 220/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8371 - val_loss: 0.3389 - val_accuracy: 0.8677\n",
            "Epoch 221/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8475 - val_loss: 0.3382 - val_accuracy: 0.8574\n",
            "Epoch 222/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3803 - accuracy: 0.8381 - val_loss: 0.3436 - val_accuracy: 0.8542\n",
            "Epoch 223/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8385 - val_loss: 0.3418 - val_accuracy: 0.8667\n",
            "Epoch 224/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3849 - accuracy: 0.8423 - val_loss: 0.3426 - val_accuracy: 0.8538\n",
            "Epoch 225/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3742 - accuracy: 0.8499 - val_loss: 0.3384 - val_accuracy: 0.8603\n",
            "Epoch 226/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8446 - val_loss: 0.3798 - val_accuracy: 0.8644\n",
            "Epoch 227/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8394 - val_loss: 0.3539 - val_accuracy: 0.8559\n",
            "Epoch 228/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8510 - val_loss: 0.3374 - val_accuracy: 0.8625\n",
            "Epoch 229/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8202 - val_loss: 0.3642 - val_accuracy: 0.8673\n",
            "Epoch 230/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8542 - val_loss: 0.3454 - val_accuracy: 0.8694\n",
            "Epoch 231/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.8401 - val_loss: 0.3506 - val_accuracy: 0.8557\n",
            "Epoch 232/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3792 - accuracy: 0.8547 - val_loss: 0.3347 - val_accuracy: 0.8642\n",
            "Epoch 233/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8283 - val_loss: 0.3458 - val_accuracy: 0.8700\n",
            "Epoch 234/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8420 - val_loss: 0.3400 - val_accuracy: 0.8613\n",
            "Epoch 235/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8420 - val_loss: 0.3402 - val_accuracy: 0.8634\n",
            "Epoch 236/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8452 - val_loss: 0.3507 - val_accuracy: 0.8577\n",
            "Epoch 237/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8380 - val_loss: 0.3789 - val_accuracy: 0.8681\n",
            "Epoch 238/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8376 - val_loss: 0.3413 - val_accuracy: 0.8670\n",
            "Epoch 239/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8409 - val_loss: 0.3394 - val_accuracy: 0.8639\n",
            "Epoch 240/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3943 - accuracy: 0.8390 - val_loss: 0.3409 - val_accuracy: 0.8606\n",
            "Epoch 241/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8327 - val_loss: 0.3430 - val_accuracy: 0.8652\n",
            "Epoch 242/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8384 - val_loss: 0.3570 - val_accuracy: 0.8553\n",
            "Epoch 243/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8420 - val_loss: 0.3388 - val_accuracy: 0.8628\n",
            "Epoch 244/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8297 - val_loss: 0.3691 - val_accuracy: 0.8692\n",
            "Epoch 245/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8442 - val_loss: 0.3393 - val_accuracy: 0.8621\n",
            "Epoch 246/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8437 - val_loss: 0.3511 - val_accuracy: 0.8703\n",
            "Epoch 247/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8426 - val_loss: 0.3427 - val_accuracy: 0.8540\n",
            "Epoch 248/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8338 - val_loss: 0.3480 - val_accuracy: 0.8544\n",
            "Epoch 249/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3916 - accuracy: 0.8417 - val_loss: 0.3373 - val_accuracy: 0.8640\n",
            "Epoch 250/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8394 - val_loss: 0.3360 - val_accuracy: 0.8625\n",
            "Epoch 251/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8404 - val_loss: 0.3404 - val_accuracy: 0.8639\n",
            "Epoch 252/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8312 - val_loss: 0.3415 - val_accuracy: 0.8628\n",
            "Epoch 253/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8331 - val_loss: 0.3535 - val_accuracy: 0.8703\n",
            "Epoch 254/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8474 - val_loss: 0.3361 - val_accuracy: 0.8668\n",
            "Epoch 255/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8446 - val_loss: 0.3407 - val_accuracy: 0.8632\n",
            "Epoch 256/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.8616 - val_loss: 0.3538 - val_accuracy: 0.8567\n",
            "Epoch 257/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3756 - accuracy: 0.8469 - val_loss: 0.3442 - val_accuracy: 0.8693\n",
            "Epoch 258/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8341 - val_loss: 0.3443 - val_accuracy: 0.8664\n",
            "Epoch 259/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8531 - val_loss: 0.3469 - val_accuracy: 0.8551\n",
            "Epoch 260/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3763 - accuracy: 0.8474 - val_loss: 0.3426 - val_accuracy: 0.8704\n",
            "Epoch 261/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8350 - val_loss: 0.3394 - val_accuracy: 0.8648\n",
            "Epoch 262/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8416 - val_loss: 0.3520 - val_accuracy: 0.8702\n",
            "Epoch 263/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8477 - val_loss: 0.3441 - val_accuracy: 0.8674\n",
            "Epoch 264/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8328 - val_loss: 0.3465 - val_accuracy: 0.8529\n",
            "Epoch 265/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8472 - val_loss: 0.3489 - val_accuracy: 0.8558\n",
            "Epoch 266/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8312 - val_loss: 0.3480 - val_accuracy: 0.8693\n",
            "Epoch 267/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8426 - val_loss: 0.3382 - val_accuracy: 0.8675\n",
            "Epoch 268/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8395 - val_loss: 0.3477 - val_accuracy: 0.8546\n",
            "Epoch 269/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8337 - val_loss: 0.3394 - val_accuracy: 0.8647\n",
            "Epoch 270/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.8561 - val_loss: 0.3385 - val_accuracy: 0.8636\n",
            "Epoch 271/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8409 - val_loss: 0.3636 - val_accuracy: 0.8537\n",
            "Epoch 272/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3775 - accuracy: 0.8387 - val_loss: 0.3410 - val_accuracy: 0.8557\n",
            "Epoch 273/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.8517 - val_loss: 0.3569 - val_accuracy: 0.8564\n",
            "Epoch 274/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4186 - accuracy: 0.8263 - val_loss: 0.3749 - val_accuracy: 0.8639\n",
            "Epoch 275/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8426 - val_loss: 0.3375 - val_accuracy: 0.8623\n",
            "Epoch 276/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8270 - val_loss: 0.3481 - val_accuracy: 0.8549\n",
            "Epoch 277/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8461 - val_loss: 0.3467 - val_accuracy: 0.8540\n",
            "Epoch 278/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8515 - val_loss: 0.3413 - val_accuracy: 0.8621\n",
            "Epoch 279/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8352 - val_loss: 0.3431 - val_accuracy: 0.8635\n",
            "Epoch 280/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8381 - val_loss: 0.3478 - val_accuracy: 0.8696\n",
            "Epoch 281/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8483 - val_loss: 0.3462 - val_accuracy: 0.8687\n",
            "Epoch 282/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3916 - accuracy: 0.8423 - val_loss: 0.3442 - val_accuracy: 0.8677\n",
            "Epoch 283/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3830 - accuracy: 0.8331 - val_loss: 0.3573 - val_accuracy: 0.8555\n",
            "Epoch 284/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8377 - val_loss: 0.3411 - val_accuracy: 0.8560\n",
            "Epoch 285/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8429 - val_loss: 0.3446 - val_accuracy: 0.8710\n",
            "Epoch 286/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8452 - val_loss: 0.3432 - val_accuracy: 0.8543\n",
            "Epoch 287/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8417 - val_loss: 0.3426 - val_accuracy: 0.8542\n",
            "Epoch 288/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3735 - accuracy: 0.8556 - val_loss: 0.3368 - val_accuracy: 0.8653\n",
            "Epoch 289/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8304 - val_loss: 0.3415 - val_accuracy: 0.8675\n",
            "Epoch 290/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8362 - val_loss: 0.3522 - val_accuracy: 0.8714\n",
            "Epoch 291/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8464 - val_loss: 0.3493 - val_accuracy: 0.8675\n",
            "Epoch 292/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8407 - val_loss: 0.3556 - val_accuracy: 0.8564\n",
            "Epoch 293/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8352 - val_loss: 0.3472 - val_accuracy: 0.8715\n",
            "Epoch 294/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8547 - val_loss: 0.3895 - val_accuracy: 0.8639\n",
            "Epoch 295/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3869 - accuracy: 0.8484 - val_loss: 0.3464 - val_accuracy: 0.8680\n",
            "Epoch 296/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8369 - val_loss: 0.3529 - val_accuracy: 0.8702\n",
            "Epoch 297/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3727 - accuracy: 0.8525 - val_loss: 0.3692 - val_accuracy: 0.8644\n",
            "Epoch 298/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.8425 - val_loss: 0.3463 - val_accuracy: 0.8551\n",
            "Epoch 299/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.8517 - val_loss: 0.3410 - val_accuracy: 0.8588\n",
            "Epoch 300/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8411 - val_loss: 0.3426 - val_accuracy: 0.8704\n",
            "Epoch 301/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8463 - val_loss: 0.3394 - val_accuracy: 0.8645\n",
            "Epoch 302/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8534 - val_loss: 0.3503 - val_accuracy: 0.8567\n",
            "Epoch 303/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8468 - val_loss: 0.3448 - val_accuracy: 0.8548\n",
            "Epoch 304/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.8461 - val_loss: 0.3374 - val_accuracy: 0.8629\n",
            "Epoch 305/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.8371 - val_loss: 0.3401 - val_accuracy: 0.8648\n",
            "Epoch 306/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3884 - accuracy: 0.8336 - val_loss: 0.3446 - val_accuracy: 0.8688\n",
            "Epoch 307/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8328 - val_loss: 0.3493 - val_accuracy: 0.8690\n",
            "Epoch 308/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8363 - val_loss: 0.3446 - val_accuracy: 0.8665\n",
            "Epoch 309/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8405 - val_loss: 0.3382 - val_accuracy: 0.8653\n",
            "Epoch 310/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8442 - val_loss: 0.3569 - val_accuracy: 0.8652\n",
            "Epoch 311/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3829 - accuracy: 0.8465 - val_loss: 0.3441 - val_accuracy: 0.8696\n",
            "Epoch 312/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8382 - val_loss: 0.3405 - val_accuracy: 0.8546\n",
            "Epoch 313/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8337 - val_loss: 0.3474 - val_accuracy: 0.8671\n",
            "Epoch 314/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8394 - val_loss: 0.3459 - val_accuracy: 0.8540\n",
            "Epoch 315/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8380 - val_loss: 0.3668 - val_accuracy: 0.8639\n",
            "Epoch 316/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8252 - val_loss: 0.3401 - val_accuracy: 0.8651\n",
            "Epoch 317/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8359 - val_loss: 0.3463 - val_accuracy: 0.8544\n",
            "Epoch 318/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8480 - val_loss: 0.3366 - val_accuracy: 0.8663\n",
            "Epoch 319/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8358 - val_loss: 0.3384 - val_accuracy: 0.8653\n",
            "Epoch 320/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.8425 - val_loss: 0.3402 - val_accuracy: 0.8617\n",
            "Epoch 321/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8514 - val_loss: 0.3373 - val_accuracy: 0.8612\n",
            "Epoch 322/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8394 - val_loss: 0.3392 - val_accuracy: 0.8619\n",
            "Epoch 323/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8213 - val_loss: 0.3379 - val_accuracy: 0.8659\n",
            "Epoch 324/1000\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3954 - accuracy: 0.8420 - val_loss: 0.3369 - val_accuracy: 0.8635\n",
            "Epoch 325/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8458 - val_loss: 0.3361 - val_accuracy: 0.8664\n",
            "Epoch 326/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8476 - val_loss: 0.3585 - val_accuracy: 0.8688\n",
            "Epoch 327/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8546 - val_loss: 0.3437 - val_accuracy: 0.8544\n",
            "Epoch 328/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8454 - val_loss: 0.3421 - val_accuracy: 0.8663\n",
            "Epoch 329/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8376 - val_loss: 0.3414 - val_accuracy: 0.8684\n",
            "Epoch 330/1000\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8526 - val_loss: 0.3378 - val_accuracy: 0.8610\n",
            "CPU times: user 2min 58s, sys: 20.5 s, total: 3min 18s\n",
            "Wall time: 2min 33s\n",
            "time: 2min 33s (started: 2020-12-29 13:27:54 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQli9dAEKW3s"
      },
      "source": [
        "##Visualisasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTfFswgRSdcL"
      },
      "source": [
        "Visualisasi nilai loss dari setiap epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvQEnHeugMnj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "0a1f451a-e10f-4dfd-89ea-cbf60a13ba05"
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\r\n",
        "plt.plot(history.history['val_loss'], label='test')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 325 ms (started: 2020-12-29 12:46:30 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB_XfCIJKaJr"
      },
      "source": [
        "##Akurasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnrVDw-WRDXg"
      },
      "source": [
        "Data Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2LOOHGTjQRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957ed65c-5073-4475-fc85-35e48756c7ec"
      },
      "source": [
        "preds = model.predict(X_test_reshaped)\r\n",
        "preds = np.round(preds, 0).reshape(preds.shape[0])\r\n",
        "acc = accuracy_score(y_test, preds)\r\n",
        "acc"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8694390715667312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        },
        {
          "output_type": "stream",
          "text": [
            "time: 247 ms (started: 2020-12-29 13:30:27 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPZLTlBURI9v"
      },
      "source": [
        "Data Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jlfGxtprtqi",
        "outputId": "893484a5-cc81-49a1-be7a-201bc7d8d9d2"
      },
      "source": [
        "preds = model.predict(X_train_reshaped)\r\n",
        "preds = np.round(preds, 0).reshape(preds.shape[0])\r\n",
        "acc = accuracy_score(y_train, preds)\r\n",
        "acc"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8769751693002258"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        },
        {
          "output_type": "stream",
          "text": [
            "time: 109 ms (started: 2020-12-29 13:30:28 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}